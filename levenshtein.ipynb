{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.load_session('user_and_course_dfs.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "from itertools import combinations \n",
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run heatmap_utilities.ipynb\n",
    "%run other_graphing_utilities.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_file = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_levenshtein_dist_resources(u1, u2):\n",
    "    if not hasattr(get_levenshtein_dist_resources, 'similarities'):\n",
    "        get_levenshtein_dist_resources.similarities = collections.defaultdict(list)\n",
    "    \n",
    "    assert (u1.user.iloc[0] != u2.user.iloc[0])\n",
    "\n",
    "    resources_used = u1.display_name.append(u2.display_name).unique()\n",
    "    resource_ids = {r: i for r, i in zip(resources_used, range(len(resources_used)))}\n",
    "    \n",
    "    resources_u1 = \"\".join([str(resource_ids[r]) for r in u1.display_name.unique()])\n",
    "    resources_u2 = \"\".join([str(resource_ids[r]) for r in u2.display_name.unique()])\n",
    "\n",
    "    if distance(resources_u1, resources_u2) == 0:\n",
    "        # Store which users are similar\n",
    "        key1 = (u1.user.iloc[0], len(resources_u1))\n",
    "        key2 = (u2.user.iloc[0], len(resources_u2))\n",
    "        \n",
    "        if key2 not in get_levenshtein_dist_resources.similarities[key1]:\n",
    "            get_levenshtein_dist_resources.similarities[key1].append(key2)\n",
    "\n",
    "    return distance(resources_u1, resources_u2)\n",
    "\n",
    "\n",
    "def get_levenshtein_distances(data, lev_func=get_levenshtein_dist_resources):\n",
    "    users = list(pd.concat(data).user.unique())\n",
    "        \n",
    "    rng = [i for i in range(0, len(users))]\n",
    "    pairs = set(combinations(rng, 2))\n",
    "    pairs = [(i, j) for i, j in pairs if i != j]\n",
    "    \n",
    "    func = lambda d, i, j: lev_func(d[i], d[j])\n",
    "                       \n",
    "    return get_2d_vals(data, users, func, pairs)\n",
    "\n",
    "\n",
    "def get_levenshtein_dist_types(user1, user2):\n",
    "    resources_used = user1.display_name.append(user2.display_name).unique()\n",
    "    \n",
    "    types_used = get_knowledge_types_used(resources_used, resource_categories)\n",
    "    type_ids = {tuple(t): i for t, i in zip(types_used, range(len(types_used)))}\n",
    "    \n",
    "    type_strs = []\n",
    "    \n",
    "    for u in [user1, user2]:\n",
    "        u_types = get_knowledge_types_used(u.display_name.unique(), resource_categories)\n",
    "        u_types_str = \"\".join([str(type_ids[tuple(t)]) for t in u_types])\n",
    "        \n",
    "        type_strs.append(u_types_str)\n",
    "    \n",
    "    return distance(type_strs[0], type_strs[1])\n",
    "\n",
    "\n",
    "def get_levenshtein_distances_types(data):\n",
    "    return get_levenshtein_distances(data, lev_func=get_levenshtein_dist_types)\n",
    "\n",
    "def get_2d_vals(data, display_names, func, loop_pairs):\n",
    "    vals = np.zeros((len(display_names), len(display_names)))\n",
    "\n",
    "    for i, j in loop_pairs:\n",
    "        vals[i][j] += func(data, i, j)\n",
    "        \n",
    "    return display_names, vals\n",
    "def broken_y_bar_histogram_df(flattened, bins):\n",
    "    # TODO: make this simpler wiithout two calls to np.histogram\n",
    "    vals, divisions = map(list, np.histogram(flattened, bins=bins))\n",
    "    divisions = [int(d) for d in divisions]\n",
    "    vals, divisions = map(list, np.histogram(flattened, bins=divisions))\n",
    "    \n",
    "    # for some reason, numpy returns zero in its values for the histogram function...\n",
    "    i = 0\n",
    "\n",
    "    while i < len(vals):\n",
    "        if not vals[i]:\n",
    "            del vals[i]\n",
    "            del divisions[i]\n",
    "            i -= 1\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "    vals.append(0)\n",
    "\n",
    "    return pd.DataFrame(zip(divisions, vals)).set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_levenshtein_distances_names, resource_levenshtein_distances = get_levenshtein_distances(user_urls_dfs)\n",
    "type_levenshtein_distances_names, type_levenshtein_distances = get_levenshtein_distances_types(user_urls_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Massive Heatmap. Do not accidentally run.\n",
    "\n",
    "# plot_2d_values_heatmap(user_urls_dfs, func=get_levenshtein_distances, \n",
    "#                        xlabel=\"User A\", ylabel=\"User B\", title_name=\"All Users\",\n",
    "#                        figsize=(400, 400), font_scale=2.5,\n",
    "#                        unit=\"Levenshtein Distance\", quantile=False,\n",
    "#                        fig_size_inches=(140, 180), dpi=300, transpose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 50\n",
    "plot_2d_values_heatmap(user_urls_dfs[0:n_users], func=get_levenshtein_distances_types, \n",
    "                       xlabel=\"User A\", ylabel=\"User B\", title_name=\"Sample {} Users\".format(n_users),\n",
    "                       figsize=(10, 10), font_scale=1,\n",
    "                       unit=\"Levenshtein Distance (Knowledge Type)\", quantile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 50\n",
    "plot_2d_values_heatmap(user_urls_dfs[0:n_users], func=get_levenshtein_distances, \n",
    "                       xlabel=\"User A\", ylabel=\"User B\", title_name=\"Sample {} Users\".format(n_users),\n",
    "                       figsize=(10, 10), font_scale=1,\n",
    "                       unit=\"Levenshtein Distance\", quantile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev_dist_by_type_flat = type_levenshtein_distances[np.triu_indices(len(type_levenshtein_distances), k=1)]\n",
    "dists_type_df = broken_y_bar_histogram_df(lev_dist_by_type_flat, 70)\n",
    "\n",
    "plot_broken_y_bar(\n",
    "    dists_type_df, lims=[(0, 500), (700, 9000)], \n",
    "    xlabel=\"Levenshtein Distance (Type)\", ylabel=\"Occurences\", \n",
    "    ylabel_loc=(-6, 570), figsize=(10, 10), breakline_len=.01,\n",
    "    width=1, align='edge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev_dist_by_resource_flat = resource_levenshtein_distances[np.triu_indices(len(resource_levenshtein_distances), k=1)]\n",
    "dists_df = broken_y_bar_histogram_df(lev_dist_by_resource_flat, 70)\n",
    "\n",
    "plot_broken_y_bar(\n",
    "    dists_df, lims=[(0, 1100), (2000, 7100)], \n",
    "    xlabel=\"Levenshtein Distance (Resource)\", ylabel=\"Occurences\", \n",
    "    ylabel_loc=(-6, 570), figsize=(10, 5), breakline_len=.01,\n",
    "    width=1, align='edge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_levenshtein_distances(user_urls_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(get_levenshtein_dist_resources.similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_resources = 0\n",
    "\n",
    "grouped_user = pd.concat(user_urls_dfs, sort=False).groupby(by='user')\n",
    "\n",
    "max_all_indices = 0\n",
    "\n",
    "for user, similarities in get_levenshtein_dist_resources.similarities.items():\n",
    "    if user[1] >= threshold_resources:\n",
    "        print(\"user: \" + user[0], \"\\nresources:\")\n",
    "        for k, v in grouped_user:\n",
    "            if k == user[0]:\n",
    "                max_index = 0\n",
    "                \n",
    "                for r in v.display_name.unique():\n",
    "                    try:\n",
    "                        index = resource_order.index(r)\n",
    "                        print(r + \", index: \" + str(index))\n",
    "                        max_index = max(max_index, index)\n",
    "                        \n",
    "                    except ValueError:\n",
    "                        print(r + \", index not found\")\n",
    "                        \n",
    "                print(\"Max Index: \" + str(max_index))\n",
    "                \n",
    "                max_all_indices = max(max_all_indices, max_index)\n",
    "                \n",
    "        print(\"\\nsimilarities: \")\n",
    "        \n",
    "        for s in similarities:\n",
    "            for k, v in grouped_user:\n",
    "                if k == s[0]:\n",
    "                    print(k)\n",
    "                    \n",
    "        print('\\n--------------------------------------------------\\n')\n",
    "    \n",
    "print(\"Max of all indices = \" + str(max_all_indices))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_levenshtein_distances_names, resource_levenshtein_distances = get_levenshtein_distances(ai_edx_dfs)\n",
    "type_levenshtein_distances_names, type_levenshtein_distances = get_levenshtein_distances_types(ai_edx_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev_dist_by_resource_flat = resource_levenshtein_distances[np.triu_indices(len(resource_levenshtein_distances), k=1)]\n",
    "dists_df = broken_y_bar_histogram_df(lev_dist_by_resource_flat, 70)\n",
    "\n",
    "plot_broken_y_bar(\n",
    "    dists_df, lims=[(0, 1100), (2000, 7100)], \n",
    "    xlabel=\"Levenshtein Distance (Resource)\", ylabel=\"Occurences\", \n",
    "    ylabel_loc=(-6, 570), figsize=(10, 5), breakline_len=.01,\n",
    "    width=1, align='edge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
