{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from utilities import *\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backups(folder, keep_duplicates=True):\n",
    "    \"\"\"Return a dataframe representing backups in a folder sorted based on time created.\n",
    "\n",
    "    Create a pandas dataframe representing backup files in a given folder based\n",
    "    on the time created, the name of the backup file (excluding the path) and \n",
    "    the number of each node type in the backup file represented as a dictionary. \n",
    "    If `keep_duplicates` is true, then any duplicate rows will be removed. This \n",
    "    is determined by the number of each node type and the backup file name. The\n",
    "    purpose of this is to not count a save if the user is idle and not changing\n",
    "    the file.\n",
    "\n",
    "    :param folder: The folder to search for backup files.\n",
    "    :param keep_duplicates: Whether to keep duplicate data rows.\n",
    "    :returns: Pandas dataframe representing the backups.\n",
    "    :rtype: pandas.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    backups = []\n",
    "\n",
    "    for f in Path(folder).rglob(\"*.backup\"):\n",
    "        # Ignore relative path sequences\n",
    "        f_str = str(f).replace('../', '')\n",
    "        split = f_str.split('.')\n",
    "        ext = split[1]\n",
    "        name = \"{}.{}\".format(split[0], split[1])\n",
    "        time = get_time_from_file_name(get_file_name(f))\n",
    "        \n",
    "        try:\n",
    "            backups.append((time, name, NODE_FUNCS[ext](str(f))))\n",
    "        except ET.ParseError as e:\n",
    "            pass\n",
    "\n",
    "    backups.sort(key=lambda x: x[0])\n",
    "\n",
    "    df = pd.DataFrame(backups, columns=['time', 'name', 'nodes'])\n",
    "\n",
    "    if not keep_duplicates:\n",
    "        df['nodes_str'] = df['nodes'].astype(str)\n",
    "        df = df.drop_duplicates(subset=['name', 'nodes_str'])\n",
    "        df = df.drop(columns='nodes_str')\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_dist(to_plot, ax, bins, title_format, all_key, xlabel=\"Ratio\", ylabel=\"Frequency\"):\n",
    "    \"\"\"Plot a histogram graph of distributions.\n",
    "\n",
    "    Given a plot, plot histogram subplots for each index of the dictionary\n",
    "    `to_plot`. Define a key for the dictionary of all values in each key\n",
    "    of data. Each subplot title will be `title_format` with their respective\n",
    "    key in the dictionary formatted into the title.\n",
    "\n",
    "    :param to_plot: The data to plot\n",
    "    :param ax: The matplotlib axis to plot\n",
    "    :param bins: The number of bins per graph\n",
    "    :param title_format: The format for the title of each subplot\n",
    "    :param all_key: The name to give the data entry of all data points.\n",
    "\n",
    "    \"\"\"\n",
    "    index = 0\n",
    "\n",
    "    for key, values in to_plot.items():\n",
    "        title = title_format.format(key)\n",
    "        \n",
    "        df = normalize_data(values, bins)\n",
    "        df.plot(kind='bar', ax=ax[index], align='edge', width=1, ec=\"white\")\n",
    "        \n",
    "        format_xticks(ax[index])\n",
    "        ax[index].set(xlabel=xlabel, ylabel=ylabel, title=title)\n",
    "        \n",
    "        index += 1\n",
    "\n",
    "    edge_vals = normalize_aggregated_dict_data(to_plot, 0.05)\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(edge_vals).T\n",
    "    ax = df.plot(kind='bar', ec='white', align='edge', width=0.8, ax=ax[index])\n",
    "    ax.set(xlabel=xlabel, ylabel=ylabel, title=title_format.format(all_key))\n",
    "    \n",
    "    format_xticks(ax, exclude_final=True)\n",
    "    \n",
    "\n",
    "def empty_pair_dict_list():\n",
    "    \"\"\"Return an empty dictionary with each pair type and an empty list.\n",
    "\n",
    "    :returns: A dictionary with each pair type and an empty list\n",
    "    :rtype: Dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    return {'BKY-BKY': [], 'BKY-SCM': [], 'SCM-BKY': [], 'SCM-SCM': []}\n",
    "\n",
    "def empty_pair_dict_count():\n",
    "    \"\"\"Return an empty dictionary with each pair type and a count of 0\n",
    "\n",
    "    :returns: A dictionary with each pair type and a count of 0\n",
    "    :rtype: Dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    return {'BKY-BKY': 0, 'BKY-SCM': 0, 'SCM-BKY': 0, 'SCM-SCM': 0}\n",
    "\n",
    "def print_stats(dictionary):\n",
    "    \"\"\"Print the length, mean, and standard deviation of a dictionary's values\n",
    "\n",
    "    :param dictionary: The dictionary to print statistics of.\n",
    "\n",
    "    \"\"\"\n",
    "    for key, counts in dictionary.items():\n",
    "        print(\"{} count: {}\\n{} mean: {}\\n{} standard deviation: {}\\n\"\n",
    "              .format(key, len(counts),\n",
    "                      key, stat.mean(counts),\n",
    "                      key, stat.stdev(counts)))\n",
    "        \n",
    "def get_ext(name):\n",
    "    \"\"\"Get the extension from a file name\n",
    "\n",
    "    :param name: The name of the file\n",
    "    :returns: The extension\n",
    "    :rtype: String\n",
    "\n",
    "    \"\"\"\n",
    "    return name.split('.')[1].upper()\n",
    "\n",
    "def normalize_data(data, bins):\n",
    "    vals, edges = np.histogram(data, bins=bins)\n",
    "\n",
    "    total = sum([v for v in vals])\n",
    "\n",
    "    assert len(data) == total\n",
    "    \n",
    "    vals = [v / total for v in vals]\n",
    "    vals.append(0)\n",
    "    \n",
    "    # TODO ASSERT SUM OF VALS == 1\n",
    "    # Hard to do because vals is a list of floats\n",
    "    # Could manage all floats specially, but we don't necessarily care about\n",
    "    # 100% accurate values because they're binned\n",
    "    \n",
    "    df = pd.DataFrame(zip(edges, vals)).set_index(0)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def normalize_aggregated_dict_data(dict_data, delta_bin):\n",
    "    # Make sure only one extra tick is included over 1 \n",
    "    # so that values of 1 are included by there are no more than 1\n",
    "    # excess ticks.\n",
    "    edge_upper_bound = 1 + (3/2 * delta_bin)\n",
    "    edges = np.arange(0, edge_upper_bound, delta_bin)\n",
    "    \n",
    "    empty_dict_func = empty_pair_dict_count if 'SCM-SCM' in dict_data.keys() else empty_save_dict_count\n",
    "    \n",
    "    edge_vals = {edge: empty_dict_func() for edge in edges}\n",
    "    total = 0\n",
    "    for key, values in dict_data.items():\n",
    "        for value in values:\n",
    "            current_edge = max([edge for edge in edges if value >= edge])\n",
    "            \n",
    "            edge_vals[current_edge][key] += 1\n",
    "            total += 1\n",
    "            \n",
    "    for key, pair in edge_vals.items():\n",
    "        for k in pair.keys():\n",
    "            edge_vals[key][k] /= total\n",
    "    \n",
    "    return edge_vals\n",
    "\n",
    "def format_xticks(ax, exclude_final=False):\n",
    "    xticks = ax.get_xticklabels()\n",
    "    ticks = [str(round(float(item.get_text()), 2)) for item in xticks]\n",
    "    ticks = [t[0:4] for t in ticks]\n",
    "    if exclude_final: ticks[-1] = ''\n",
    "    ax.set_xticklabels(ticks)\n",
    "    \n",
    "def get_time_since_beginning(times, index):\n",
    "    \"\"\"Return the time between the beginning of a list of times and a time at a given index\n",
    "\n",
    "    :param times: The list of times\n",
    "    :param index: The index of the time to look at\n",
    "    :returns: The difference in time\n",
    "    :rtype: datetime.timedelta\n",
    "\n",
    "    \"\"\"\n",
    "    return (times[index] - times[0]).total_seconds()\n",
    "\n",
    "def empty_save_dict_count():\n",
    "    return {'SCM': 0, 'BKY': 0}\n",
    "\n",
    "    \n",
    "def get_project_sessions(folder, keep_duplicates=True, time_interval=TWO_HOURS):\n",
    "    \"\"\"Return a dictionary of each project backup session\n",
    "\n",
    "    Separate each projects backups into separate sessions. The default threshold\n",
    "    for a new session is 2 hours (7200 seconds) between submissions. Returns a\n",
    "    dictionary where the keys are directories to a users projects, values being\n",
    "    lists where each element of this list is a dictionary representing a session.\n",
    "    This dictionary has lists of times created and file backup names. So we return\n",
    "    a dictionary of lists of dictionaries of lists.\n",
    "    \n",
    "    :param folder: The folder where the backups are stored.\n",
    "    :param keep_duplicates: Whether to keep duplicate data.\n",
    "    :param time_interval: The threshold that defines a single session.\n",
    "    :returns: Dictionary of each project backup session.\n",
    "    :rtype: Dictionary.\n",
    "\n",
    "    \"\"\"\n",
    "    all_sessions = {}\n",
    "\n",
    "    for project in get_directories(folder):\n",
    "        backups = get_backups(project, keep_duplicates=keep_duplicates)\n",
    "\n",
    "        if not backups.size: continue\n",
    "\n",
    "        names = list(backups['name'])\n",
    "        times = list(backups['time'])\n",
    "\n",
    "        sessions = []\n",
    "        session_start = 0\n",
    "        \n",
    "        for i in range(len(times) - 1):\n",
    "            if (times[i+1] - times[i]).total_seconds() > time_interval:\n",
    "                sessions.append({'time': times[session_start: i+1],\n",
    "                                 'name': names[session_start: i+1]})\n",
    "\n",
    "                session_start = i + 1\n",
    "        \n",
    "        sessions.append({'time': times[session_start:],\n",
    "                         'name': names[session_start:]})\n",
    "        \n",
    "        user = project.split('/')[-2]\n",
    "\n",
    "        all_sessions[user + '/' + project] = sessions\n",
    "\n",
    "    return all_sessions\n",
    "\n",
    "def get_time_between_saves(folder, keep_duplicates=True):\n",
    "    diffs = []\n",
    "\n",
    "    for project in get_directories(folder):\n",
    "        backups = get_backups(project, keep_duplicates=keep_duplicates)\n",
    "\n",
    "        if not backups.size: continue\n",
    "\n",
    "        times = list(backups['time'])\n",
    "        \n",
    "        for i in range(len(times) - 1):\n",
    "            diffs.append((times[i+1] - times[i]).total_seconds())\n",
    "\n",
    "    return diffs\n",
    "\n",
    "\n",
    "def get_all_times_and_names(project):\n",
    "    \"\"\"Get a list of names and times backups files were created in a project.\n",
    "\n",
    "    Get a list of names for each backup and a list of times the backups were\n",
    "    created in a single project. A project is a dictionary with the times\n",
    "    created and the names of each file in the project. Returns a tuple of \n",
    "    the form `(times, names)`.\n",
    "\n",
    "    :param project: The individual project.\n",
    "    :returns: The names and times backup files were created\n",
    "    :rtype: Tuple\n",
    "\n",
    "    \"\"\"\n",
    "    all_names = []\n",
    "    all_times = []\n",
    "    \n",
    "    for session in project:\n",
    "        all_names.extend(session['name'])\n",
    "        all_times.extend(session['time'])\n",
    "\n",
    "    return all_times, all_names\n",
    "\n",
    "def get_backup_pairs(folder, keep_duplicates=True):\n",
    "    \"\"\"Return how often each different backup file pair occurs.\n",
    "    \n",
    "    :param folder: The folder where the backup files are contained.\n",
    "    :param keep_duplicates: Whether to store duplicate data\n",
    "    :returns: Dictionary with how often each type of backup pair occurs.\n",
    "    :rtype: Dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    pairs = empty_pair_dict_count()\n",
    "    \n",
    "    for project in get_directories(folder):\n",
    "        pair_counts = get_backup_pairs_per_project(project, keep_duplicates)\n",
    "        \n",
    "        for key, value in pair_counts.items():\n",
    "            pairs[key] += value\n",
    "            \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "[np.random.randn(n) for n in [10000, 5000, 2000]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
