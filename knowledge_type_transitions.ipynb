{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.load_session('user_and_course_dfs.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run other_graphing_utilities.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_counts(data, keep_reloads=False, session_threshold=TWO_HOURS):\n",
    "    occurences = get_durations(data, session_threshold=session_threshold).groupby(['from', 'to'])\n",
    "\n",
    "    counts = occurences.size().to_frame(name='count').reset_index()\n",
    "    \n",
    "    return result_of_keep_reloads(keep_reloads, counts)\n",
    "\n",
    "def get_durations(data, session_threshold=TWO_HOURS):\n",
    "    durations = []\n",
    "\n",
    "    for u in data:\n",
    "        for i in range(u.time.count() - 1):\n",
    "            # For some reason, despite the timezones already being in UTC, they have to be converted\n",
    "            # again. Not sure if a bug or something is modifying them between assignment and here\n",
    "            time_diff = (u.time.iloc[i+1].tz_convert('UTC') - u.time.iloc[i].tz_convert('UTC')).total_seconds()\n",
    "            if time_diff > session_threshold: time_diff = 0\n",
    "            \n",
    "            durations.append((u.display_name.iloc[i], u.display_name.iloc[i+1], time_diff))\n",
    "\n",
    "    return pd.DataFrame(durations, columns=['from', 'to', 'duration'])\n",
    "\n",
    "def result_of_keep_reloads(keep_reloads, transitions):\n",
    "    if keep_reloads: return transitions\n",
    "    \n",
    "    if len(transitions): return transitions[transitions['from'] != transitions['to']]\n",
    "    \n",
    "    else: return transitions\n",
    "\n",
    "def analyze_knowledge_types(data, avg_duration_threshold=DURATION_AVERAGE_THRESHOLD):\n",
    "    transitions_from_to = {ktype: {kt: 0 for kt in KTYPES} for ktype in KTYPES}\n",
    "\n",
    "    categories_avg_duration_over_threshold = {kt: 0 for kt in KTYPES}\n",
    "    resources_avg_duration_over_threshold = []\n",
    "\n",
    "    total_of_each_category = {kt: 0 for kt in KTYPES}\n",
    "\n",
    "    transition_counts = get_transition_counts(data)\n",
    "\n",
    "    for resource, transitions in transition_counts.groupby(\"from\"):\n",
    "        types = get_knowledge_types_used_single(resource, resource_categories)\n",
    "        categories = get_knowledge_type_categories(types)\n",
    "\n",
    "        duration_avg = int(duration_avgs[resource])\n",
    "\n",
    "        over_avg_duration_threshold = False\n",
    "\n",
    "        if duration_avg > avg_duration_threshold:\n",
    "            resources_avg_duration_over_threshold.append(resource)\n",
    "            over_avg_duration_threshold = True\n",
    "\n",
    "        for c in categories:\n",
    "            if over_avg_duration_threshold:\n",
    "                categories_avg_duration_over_threshold[c] += 1\n",
    "\n",
    "        for _, transition in transitions.iterrows():\n",
    "            to_types = get_knowledge_types_used_single(transition.to, resource_categories)\n",
    "            to_categories = get_knowledge_type_categories(to_types)\n",
    "\n",
    "            from_index = get_resource_index(resource)\n",
    "            to_index = get_resource_index(transition.to)\n",
    "\n",
    "            for from_c in categories:\n",
    "                for to_c in to_categories:\n",
    "                    total_of_each_category[from_c] += 1\n",
    "                    total_of_each_category[to_c] += 1\n",
    "                    transitions_from_to[from_c][to_c] += 1\n",
    "\n",
    "    percents = []\n",
    "    all_total = sum(total_of_each_category.values())\n",
    "    percents.append([\"{:0.2f}\".format(v/all_total) for v in total_of_each_category.values()])\n",
    "    \n",
    "    for key, value in transitions_from_to.items():\n",
    "        inner_percents = []\n",
    "        total = sum(value.values())\n",
    "\n",
    "        for k, v in value.items():\n",
    "            inner_percents.append(\"{:0.2f}\".format(v/total))\n",
    "\n",
    "        percents.append(inner_percents)\n",
    "    \n",
    "    columns = list(transitions_from_to.keys())\n",
    "    percent_df = pd.DataFrame(data=percents, \n",
    "                              index=['All'] + columns,\n",
    "                              columns=columns)\n",
    "    \n",
    "    return transitions_from_to, percent_df, \\\n",
    "           categories_avg_duration_over_threshold, \\\n",
    "           resources_avg_duration_over_threshold\n",
    "\n",
    "def get_resource_index(resource, row=None, from_to=None):\n",
    "    try:\n",
    "        if row is not None:\n",
    "            if not from_to:\n",
    "                print(\"You must specify either the 'from' or 'to' column\")\n",
    "                return\n",
    "\n",
    "            return resource_order.index(row[from_to])\n",
    "        elif resource:\n",
    "            return resource_order.index(resource)\n",
    "        else:\n",
    "            print(\"You must specify either a resource or a row\")\n",
    "            return\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return np.nan\n",
    "\n",
    "def get_resource_duration_sums(d_df):\n",
    "    all_resource_time = d_df.groupby(['from'])\n",
    "    \n",
    "    return all_resource_time.duration.sum().sort_values(ascending=False)    \n",
    "\n",
    "def get_resource_duration_avgs(d_df):\n",
    "    all_resource_time = d_df.groupby(['from'])\n",
    "    return all_resource_time.duration.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_durations = get_resource_duration_sums(get_durations(user_urls_dfs))\n",
    "resource_counts = pd.concat(user_urls_dfs).display_name.value_counts()\n",
    "resource_duration_avgs = get_resource_duration_avgs(get_durations(user_urls_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transition_counts = get_transition_counts(user_urls_dfs)\n",
    "display(transition_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transition_counts['from_index'] = transition_counts.apply(\n",
    "    lambda x: get_resource_index(None, row=x, from_to=FROM), \n",
    "    axis=1)\n",
    "\n",
    "transition_counts['to_index'] = transition_counts.apply(\n",
    "    lambda x: get_resource_index(None, row=x, from_to=TO), \n",
    "    axis=1)\n",
    "\n",
    "\n",
    "transition_counts = transition_counts.dropna()\n",
    "transition_counts = transition_counts[transition_counts['from_index'] > transition_counts['to_index']]\n",
    "transition_counts = transition_counts.sort_values('count')\n",
    "transition_counts = transition_counts[transition_counts['count'] > 1]\n",
    "\n",
    "transitions_median = transition_counts['count'].median()\n",
    "transitions_mean = transition_counts['count'].mean()\n",
    "\n",
    "print(transitions_median)\n",
    "print(transitions_mean)\n",
    "display(transition_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_resource_duration = resource_durations.sum()\n",
    "\n",
    "ratios = [d/total_resource_duration for d in resource_durations]\n",
    "scale = 1/max(ratios)\n",
    "\n",
    "scaled_medians = []\n",
    "\n",
    "for display_name, ratio in zip(resource_durations.index, ratios):\n",
    "    scaled_medians.append((display_name, float(transitions_median*ratio*scale)))\n",
    "    \n",
    "scaled_medians_df = pd.DataFrame(scaled_medians, columns=['resource', 'scaled median']).set_index('resource')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(scaled_medians_df)\n",
    "scaled_medians_df.to_csv(path_or_buf='tmp/scaled_medians.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#medians = dict(scaled_medians)\n",
    "duration_avgs = dict(resource_duration_avgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ai only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions, percents, categories_over, resources_over = analyze_knowledge_types(user_urls_dfs)\n",
    "display(percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = collections.defaultdict(int)\n",
    "num_per_type = collections.defaultdict(int)\n",
    "\n",
    "for i in range(len(resource_order) - 1):\n",
    "    r1 = resource_order[i]\n",
    "    r2 = resource_order[i+1]\n",
    "\n",
    "    r1_ktypes = get_knowledge_type_categories(get_knowledge_types_used_single(r1, resource_categories))\n",
    "    r2_ktypes = get_knowledge_type_categories(get_knowledge_types_used_single(r2, resource_categories))\n",
    "\n",
    "    for t in r1_ktypes:\n",
    "        num_per_type[t] += 1\n",
    "        if t in r2_ktypes:\n",
    "            repeats[t] += 1\n",
    "\n",
    "display(repeats)\n",
    "display(num_per_type)\n",
    "\n",
    "ratios = {}\n",
    "\n",
    "for key in repeats:\n",
    "    ratios[key] = repeats[key] / num_per_type[key]\n",
    "    print(repeats[key], num_per_type[key])\n",
    "    \n",
    "pd.DataFrame(ratios, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ai+edx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_durations = get_resource_duration_sums(get_durations(user_urls_dfs))\n",
    "resource_counts = pd.concat(user_urls_dfs).display_name.value_counts()\n",
    "resource_duration_avgs = get_resource_duration_avgs(get_durations(user_urls_dfs))\n",
    "duration_avgs = dict(resource_duration_avgs)\n",
    "transitions, percents, categories_over, resources_over = analyze_knowledge_types(user_urls_dfs)\n",
    "percents = percents.reindex(columns=['factual', 'conceptual', 'procedural']) \\\n",
    "                   .reindex(index=['All', 'factual', 'conceptual', 'procedural'])\n",
    "percents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
